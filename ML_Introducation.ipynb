{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is ML?\n",
    "#mathematical model\n",
    "\n",
    "\n",
    "\n",
    "#Types ? ARTIFICIAL INTELLIGENCe\n",
    "#supervised learning ==> Target feature is available\n",
    "#Un supervised learning ==> low value, medium value, high value No target available\n",
    "#Semi supervised ===> supervised + unsupervised\n",
    "#Reinforcement === > learning based on environment, agent \n",
    "#Deep learning ===> Mathematical neurons Brain neurons ==> feautre engineeing \n",
    "#NLTK ==> natural language processing \n",
    "#Computer vision\n",
    "#Recommendation engine\n",
    "#Time series forecasting \n",
    "#Forecasting and prediction\n",
    "\n",
    "#Simple models are always better\n",
    "\n",
    "\n",
    "#kinds:\n",
    "#Regression\n",
    "#Linear regression\n",
    "\n",
    "\n",
    "#Classification algorithm\n",
    "#Logistic regression\n",
    "\n",
    "\n",
    "#Clustering\n",
    "#k means clustering\n",
    "\n",
    "#flow ?\n",
    "\n",
    "#Data collection ===> Data Engineers\n",
    "#Preprocessing ===> numpy pandas seaborn matplotlib  ====> PART 1\n",
    "#Exploratory Data Analysis ==> Univarite, Bivariate, Multivariate, Statistics,  ===> PART 2\n",
    "#Feature Engineering  ===> Understand and create new features for model creation\n",
    "#scaling normalize ===> MinMax scalar (0 to 1) or standardize  ==> Standard scalar (-1 to +1) and numerical value conversion\n",
    "#linear regression, logistic, naive bayes, \n",
    "#some algorithms doesnt requires decision tree, random forest \n",
    "#Evaluation metrics accuracy, loss function \n",
    "#Regression : Mean square Error, Root Mean square Error, MAPE ,mean absolute per error\n",
    "#classification: accuracy, precision, sensitivity, specificity, recall, F1 score \n",
    "\n",
    "\n",
    "#Datascience ?\n",
    "\n",
    "\n",
    "\n",
    "#Terms:\n",
    "\n",
    "#dimersionality reduction\n",
    "# curse of dimensions ===> More features or more columns ===> model tends overfit low bias (training high accuracy)and high variance (less accuracy)\n",
    "\n",
    "\n",
    "#scaling\n",
    "#Standard Vs Minmax\n",
    "\n",
    "#test train split  ==> sklearn\n",
    "#split test train accuracy\n",
    "\n",
    "\n",
    "#cross validation ==> k fold validation, one fold cross validation\n",
    "#testing\n",
    "#9 8 7 6 5 4 3 2 1 5 6 7 8 \n",
    "\n",
    "\n",
    "#Hyperparameter tuning\n",
    "#all the parameter ==> good parameter\n",
    "\n",
    "\n",
    "#pandas profiling \n",
    "#https://towardsdatascience.com/exploratory-data-analysis-with-pandas-profiling-de3aae2ddff3#:~:text=Pandas%20profiling%20is%20an%20open,a%20few%20lines%20of%20code.&text=In%20short%2C%20what%20pandas%20profiling,the%20distribution%20of%20each%20variable.\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
